<!DOCTYPE html>
<html>
<head>
  <title>Team Purple AI Interviewer</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      padding: 30px;
      background-color: #f4f4f4;
    }
    h1 {
      color: #4b0082;
    }
    button {
      padding: 10px 20px;
      font-size: 16px;
      margin-top: 20px;
    }
    #log {
      margin-top: 20px;
      background: #fff;
      padding: 15px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }
    img.logo {
      max-width: 200px;
      margin-bottom: 20px;
    }
    video {
      margin-top: 20px;
      border-radius: 10px;
      box-shadow: 0 0 10px rgba(0,0,0,0.1);
    }
  </style>
</head>
<body>
  <img src="logo.png" alt="Company Logo" class="logo" />
  <h1>ðŸ§  Team Purple AI Interviewer</h1>
  <p>Click the button below to start your voice interview.</p>
  <button onclick="startInterview()">Start Interview</button>

  <div id="log"></div>

  <!-- ðŸ“¸ Webcam preview -->
  <video id="webcam" autoplay playsinline width="320" height="240" muted></video>

  <!-- âºï¸ Download link -->
  <a id="downloadLink" style="display:none;" download="interview_recording.webm">Download Recording</a>

  <script>
    const questions = [
      "Hello, I am Team Purple AI Interviewer. We are sorry for the inconvenience caused by taking re-interviews due to an emergency. Let's start the interview.",
      "Tell me about yourself.",
      "What are your strengths and weaknesses?",
      "Describe a challenging technical problem you solved recently.",
      "Where do you see yourself in 5 years?",
      "Thank you for your time. We'll get back to you soon!"
    ];

    let currentQuestion = 0;
    let mediaRecorder;
    let recordedChunks = [];

    function speak(text) {
      const utterance = new SpeechSynthesisUtterance(text);
      speechSynthesis.speak(utterance);
    }

    async function startInterview() {
      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
      document.getElementById('webcam').srcObject = stream;

      recordedChunks = [];
      mediaRecorder = new MediaRecorder(stream);

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) recordedChunks.push(e.data);
      };

      mediaRecorder.onstop = () => {
        const blob = new Blob(recordedChunks, { type: 'video/webm' });
        const url = URL.createObjectURL(blob);
        const downloadLink = document.getElementById('downloadLink');
        downloadLink.href = url;
        downloadLink.style.display = 'inline';
      };

      mediaRecorder.start();

      askNextQuestion();
    }

    function askNextQuestion() {
      if (currentQuestion >= questions.length) {
        document.getElementById('log').innerHTML += "<p>âœ… Interview completed. Thank you!</p>";
        stopInterview();
        return;
      }

      const question = questions[currentQuestion];
      speak(question);
      document.getElementById('log').innerHTML += `<p><strong>Q:</strong> ${question}</p>`;
      currentQuestion++;
      
      setTimeout(askNextQuestion, 6000); // Wait ~6 seconds per question
    }

    function stopInterview() {
      if (mediaRecorder && mediaRecorder.state !== "inactive") {
        mediaRecorder.stop();
      }
    }
  </script>
</body>
</html>
